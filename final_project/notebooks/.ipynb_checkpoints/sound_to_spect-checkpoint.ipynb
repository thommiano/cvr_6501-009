{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchaudio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/data/datasets/sound_datasets/pytorch_UrbanSound8K/audio/trainset/street_music/101848-9-0-0.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate time it will take to generate spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_log = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03776431083679199\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# torchaudio.load() is 100x faster than librosa.load()\n",
    "test_sound_2, _ = torchaudio.load(test_path)\n",
    "sr = int(_/2)\n",
    "tn = time.time()\n",
    "tt = tn-t0\n",
    "time_log += tt\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05403327941894531\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "n_mels = 512 # perhaps twice as long as 128\n",
    "S = librosa.feature.melspectrogram(y=test_sound_2.numpy()[:,0], sr=sr, n_mels=n_mels,fmax=11000)\n",
    "tn = time.time()\n",
    "tt = tn-t0\n",
    "time_log += tt\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3176882266998291\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# librosa.display.specshow(librosa.power_to_db(S,ref=np.max),fmax=10000)\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.ioff()\n",
    "librosa.display.specshow(librosa.power_to_db(S,ref=np.max),fmax=10000)\n",
    "\n",
    "plt.axis('off') # Removes black border\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../test_output_spectrogram.png\",bbox_inches='tight',pad_inches=-0.05,transparency=True)\n",
    "\n",
    "tn = time.time()\n",
    "tt = tn-t0\n",
    "time_log += tt\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4094858169555664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should take about a minute to convert all sounds into histograms\n",
    "time_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate spectrograms for directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spectrogram(sound_in, img_out):\n",
    "    \n",
    "    sound_tensor, _ = torchaudio.load(sound_in)\n",
    "    sr = int(_/2)\n",
    "\n",
    "    y = sound_tensor.numpy()[:,0]\n",
    "    n_mels = 512 # perhaps twice as long as 128\n",
    "    fmax = 11000\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,fmax=fmax)\n",
    "\n",
    "    plt.ioff()\n",
    "    librosa.display.specshow(librosa.power_to_db(S,ref=np.max),fmax=10000)\n",
    "    plt.axis('off') # Removes black border\n",
    "    plt.tight_layout()\n",
    "    #out = \"../../test_output_spectrogram.png\"\n",
    "    plt.savefig(img_out,bbox_inches='tight',pad_inches=-0.05,transparency=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "src_path = \"/data/datasets/sound_datasets/pytorch_UrbanSound8K/audio/trainset/\"\n",
    "out_path = \"/data/datasets/sound_datasets/pytorch_UrbanSound8K/image/trainset/\"\n",
    "\n",
    "# 101848-9-0-0.wav\n",
    "\n",
    "for root, dirs, _ in os.walk(src_path):  \n",
    "    for class_dir in dirs:\n",
    "        files = os.listdir(os.path.join(dir_path, class_dir))\n",
    "        for file in files:\n",
    "            \n",
    "            sound_in = os.path.join(src_path,class_dir,file)\n",
    "            file_name = file[:-4] # removes file type\n",
    "            img_out = os.path.join(out_path,class_dir,file_name,\".png\")\n",
    "            \n",
    "            generate_spectrogram(sound_in,img_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
