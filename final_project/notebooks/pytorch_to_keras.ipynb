{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Downloading h5py-2.7.1-cp35-cp35m-manylinux1_x86_64.whl (5.3MB)\n",
      "\u001b[K    100% |################################| 5.3MB 287kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.5/dist-packages (from h5py)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from h5py)\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-2.7.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install keras\n",
    "# !pip install tensorflow\n",
    "# !pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def pyt_to_keras(pytorch_model, keras_model):\n",
    "  \"\"\"\n",
    "    Given a PyTorch model, this method transfers the weight to\n",
    "    a Keras Model (with backend TensorFlow) with the same architecture.\n",
    "    Assumptions:\n",
    "      1. The corresponding layer names in both the models will be the same\n",
    "      2. Will throw KeyError when layer is there in Keras model but not in PyTorch model,\n",
    "        otherwise, will ignore the layer.\n",
    "    Implementated Layers:\n",
    "      1. 2D Convolutional Layer\n",
    "      2. Fully Connected Layer\n",
    "    Eg:\n",
    "    class PyNet(nn.Module):\n",
    "      def __init__(self):\n",
    "          super(PyNet, self).__init__()\n",
    "          self.conv_1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(3, 4), padding=0)\n",
    "      def forward(self, x):\n",
    "          return self.conv_1(nn.ZeroPad2d((1, 2, 1, 1))(x))\n",
    "    pyt_model = PyNet()\n",
    "    a = keras.Input(shape=(5, 6, 1), name='input')\n",
    "    b = keras.layers.Conv2D(2, (3, 4), activation='linear', padding='same',\n",
    "                            name='conv_1', bias_initializer='random_uniform')(a)\n",
    "    keras_model = keras.models.Model(inputs=a, outputs=b)\n",
    "    keras_model = pyt_to_keras(pyt_model, keras_model)\n",
    "    Args:\n",
    "    :param pytorch_model: Similar model in PyTorch\n",
    "    :type pytorch_model: torch.nn.Module\n",
    "    :param keras_model: Model loaded in Keras.\n",
    "    :type keras_model: keras.models.Model\n",
    "    :return: PyTorch model with weight transferred from the Keras Model\n",
    "    :rtype: torch.nn.Module\n",
    "    \"\"\"\n",
    "  pyt_state_dict = pytorch_model.state_dict()\n",
    "  for idx, layer in enumerate(keras_model.layers):\n",
    "    if type(layer).__name__.endswith('Conv2D'):\n",
    "      # Keras 2D Convolutional layer: height * width * input channels * output channels\n",
    "      # PyTorch 2D Convolutional layer: output channels * input channels * height * width\n",
    "      name = layer.name\n",
    "      weights = np.transpose(pyt_state_dict[name + '.weight'].numpy(), (2, 3, 1, 0))\n",
    "      bias = pyt_state_dict[name + '.bias'].numpy()\n",
    "      keras_model.layers[idx].set_weights([weights, bias])\n",
    "    elif type(layer).__name__.endswith('Dense'):\n",
    "      # Keras Linear Layer: input neurons * output neurons\n",
    "      # PyTorch Linear Layer: output neurons * input neurons\n",
    "      name = layer.name\n",
    "      weights = np.transpose(pyt_state_dict[name + '.weight'].numpy(), (1, 0))\n",
    "      bias = pyt_state_dict[name + '.bias'].numpy()\n",
    "      keras_model.layers[idx].set_weights([weights, bias])\n",
    "  return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "pytorch_model = models.resnet50(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear (2048 -> 1000)\n",
      "Linear (2048 -> 10)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "print(pytorch_model.fc)\n",
    "pytorch_model.fc = nn.Linear(pytorch_model.fc.in_features, 10)\n",
    "print(pytorch_model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model.load_state_dict(torch.load('/data/datasets/sound_datasets/pytorch_UrbanSound8K/saved_models/cvr_final_project/resnet50_v2_melspect_15_968.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_pytorch_model = pyt_to_keras(pytorch_model,keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2 attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converter import pytorch_to_keras\n",
    "k_model = pytorch_to_keras((10, 32, 32,), output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pip/download.py\", line 421, in get_file_content\n",
      "    with open(url, 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'requirements.txt'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"./pytorch2keras/setup.py\", line 9, in <module>\n",
      "    reqs = [str(ir.req) for ir in install_reqs]\n",
      "  File \"./pytorch2keras/setup.py\", line 9, in <listcomp>\n",
      "    reqs = [str(ir.req) for ir in install_reqs]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pip/req/req_file.py\", line 84, in parse_requirements\n",
      "    filename, comes_from=comes_from, session=session\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pip/download.py\", line 425, in get_file_content\n",
      "    'Could not open requirements file: %s' % str(exc)\n",
      "pip.exceptions.InstallationError: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "!python3 ./pytorch2keras/setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
